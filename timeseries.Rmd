---
title: "Homework 3 - Time Series"
author: "Giorgio Ruffa"
date: "17 January 2018"
output: 
  html_document:
    includes:
      in_header: myheader.html
---
<a href="https://github.com/xmooner/IDA-TimeSeriesHomework"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>

#Introduction
This notebook was developed for the last assignment of the `Intelligent Data Analysis` course held by [Arminda Moreno Díaz](http://www.dia.fi.upm.es/es/amoreno) at UPM.

Our dataset represent the total credit to the non-financial private sector annual rate. It is a monthly time
series from January 2000 to December 2004.

The file can be found in the [page repository](https://github.com/xmooner/IDA-TimeSeriesHomework) under the name [`data_g11.xlsx`](https://github.com/xmooner/IDA-TimeSeriesHomework/blob/master/data_g11.xlsx).

# Dataset Preparation and exploration
We load the required libraries. We load the dataset and create a timeseries object with the frequency to 12 (as they are monthly data) in order to exploit seasonal plotting functions.

```{r libs, message=FALSE}
library(forecast)
library(xlsx)
library(ggplot2)
library(tseries)
library(car)
library(astsa)
library(outliers)

NPO_Time_Series=read.xlsx("data_g11.xlsx", sheetIndex = 1)
NPO_Time_Series = ts(data = NPO_Time_Series$Tasa, frequency = 12, start=c(2000,1) , end=c(2004,12), names=c("rate") )
```

Let's give a rough look to the time series.
```{r}
summary(NPO_Time_Series)
autoplot(NPO_Time_Series) 
```

The data ranges from 13.47 to 20.23 and we can immediately see that there is an inversion of trend after the beginning of 2003 and that the trend component may be the most influencing one. At first sight there is no sign of seasonal of cyclical behavior.

```{r, }
NPO.acf = acf2(NPO_Time_Series)
```

The auto-correlation plot shows a slow dumping sine, while the partial correlation plot has a sharp cutoff after one. This may suggest an ARIMA modeling using only the auto regressive component of the type AR(1) or AR(2), but we will see this later.
Another conclusion that can be taken without testing formally is that the series does not definitely look as a stationary one.

Another important decision to take is to work with an additive model or a multiplicative one. At first sight the variance does not seem to increase in a monotonic way. In fact plotting the time series or its logarithm yields two very similar graphs.
```{r, echo=FALSE}
par(mfrow=c(2,1))
plot(NPO_Time_Series)
plot(log(NPO_Time_Series))
```

Besides the scale, they look pretty much the same. So we decide to go for the additive model and save in complexity.

## Decomposition
We perform the classical decomposition in trend, seasonal and random (residual)

```{r}
NPO.decomposed = decompose(NPO_Time_Series, type= "additive")
plot(NPO.decomposed)
```

Our hunch regarding the trend is pretty clear, it shows a neat re-bounce after 2003.

Talking about the seasonal component one must be very careful. Although the pattern looks really nice, it's amplitude is one order of magnitude less that the random component.
In fact, if we subtract the seasonal component to the observed values we still obtain a pretty edgy line.

```{r}
plot(NPO_Time_Series - NPO.decomposed$seasonal)
```

Even trying with the "stl" package and tuning the "t.window" parameter yields the same results (which are not reported here).

We can get a further confirmation by using ggseasonplot and ggmonthplot
```{r, echo=FALSE}
ggmonthplot(NPO_Time_Series)
ggseasonplot(NPO_Time_Series)
```

Basically every month in the monthplot follows the trend component and there is no clear pattern at all looking at the season plot.

### Prediction
We perform some prediction using the Holt-Winters method
```{r}
NPO.HW<- HoltWinters(NPO_Time_Series)
pred.NPO.HW <- predict(NPO.HW, n.ahead=24, prediction.interval=TRUE)
plot(NPO.HW, pred.NPO.HW, ylab="Credit", xlab="", main="")
labs <- c("Observed values", "Fitted values", "Predicted intervals")
legend("bottomleft", lty=rep(1,3), col=c("black", "red", "blue"), legend=labs)
```

The model is predicting a new inversion of the trend, but still with a very large confidence interval which can include a steady climb.

# ARIMA Models and the Box-Jenkins methodology
Based on what we have learned so far we can already take some decisions.

1. The series is not stationary: we need to reduce it to a stationary one by means of differentiation
2. The series does not need a multiplicative model: we do not need a logarithmic transformation 
3. The series does not show any clear seasonality or cyclicity: no need to make a seasonal arima model
4. The auto-correlation plot shows a dumping sine and the partial correlation plot has a sharp cutoff after one: we may start to look for an AR(1) or AR(2) model.

## Making the series stationary
We will differentiate the series to make it stationary. This will also fix the degree of differentiation needed for the ARIMA model.
```{r}
tsdisplay(diff(NPO_Time_Series))
tsdisplay(diff(diff(NPO_Time_Series)))
```

From the ACF and PACF plots above we can see that a good candidate for stationarity is differentiating only once, this because all the correlations are in the confidence interval around zero while this is not true differentiating two times.
```{r}
sd(diff(NPO_Time_Series))
sd(diff(diff(NPO_Time_Series)))
```
Also, the standard deviation of the second order differentiation increases.

We run some tests to check for stationarity
```{r}
adf.test(diff(NPO_Time_Series)) #ok
pp.test(diff(NPO_Time_Series)) #ok
```

The low p-values in both tests suggest reject the null hypothesis of not stationarity.
Even the command ndiffs agrees on one order of differentiation.
```{r}
ndiffs(NPO_Time_Series)
```

So the "d" parameter of the non seasonal ARIMA model will be set to 1.

## Arima Modeling
We are going to train three models. One with p=1, one with p=2 and one using the auto.arima function which should give us further inspiration.

### AR(1)
This will be the simplest model.

```{r}
NPO.ar1=Arima(NPO_Time_Series, order=c(1,1,0))
summary(NPO.ar1)
```
We have an RMSE of 0.75 and a MAE of 0.54 to use as baseline. Please not that RMSE is more influenced by huge variations in the frequency of the residuals while MAE (mean absolute error) is more stable and always less than the RMSE. So in case that huge residuals are a cost for the model rather then the average performance, RMSE should be used, but this depends strictly on the goal of the model and on the costs associated with the error.

The quality of the model is largely impacted by the randomness of its residuals. They must be as close as possible as white noise.

All the auto correlations coefficients and the partial auto-correlation coefficients should be in the confidence range around zero.
```{r}
NPO.ar1.res.acf = acf2(NPO.ar1$residuals)
```

And they look surprisingly well.

To go further we check for the overall randomness of the coefficients with the Box test, while tuning for the degree of freedom, as specified in the documentation of the "Box.test" function.

```{r}
Box.test(NPO.ar1$residuals, lag=12, fitdf = 1)
```
We cannot discard the null hypothesis of randomness, hence we are satisfied.

Finally the residuals must follow a normal distribution. We perform the Jarque-Brera test for skewness and kurtosis.

```{r}
jarque.bera.test(NPO.ar1$residuals)
```
Which, unfortunately fails.
To try to identify the cause we plot roughly plot the distribution of the residuals and we use the qqPlot function.
```{r ,echo=FALSE}
hist(NPO.ar1$residuals,breaks = 20)
qqPlot(NPO.ar1$residuals)
```

We can see that there is a residual with a very high number close to -2.9 which is in position 6 (June 2000) and have a value of 16.
```{r}
NPO_Time_Series[6]
```

We are now entering a very sensitive and broad area: outliers in time series. There is a wide variety of 
alternatives concerning dealing with them, one thing is sure: *"[outliers] may provide useful information about the process that produced the data, and which should be taken into account when forecasting"* [(Hyndman, Athanasopoulos)](https://otexts.org/fpp2/missing-outliers.html).

Unfortunately we have little information about the origin of our dataset and further investigations are well behind the scope of this work. Hence we are going to assume that outliers are generated by errors and we can safely replace them. But how to replace them?

Simply removing them from the collection is not very wise as we should investigate further how our analysis will deal with missing values. Luckily the `tsoutliers` functions will use the [Friedman’s Super Smoother](http://fmwww.bc.edu/RePEc/bocode/s/supsmooth_doc.pdf)to identify outliers and suggest us an alternative value for replacement.
```{r}
tsoutliers(NPO_Time_Series)
```
`tsoutliers` agrees with us in the location of the outlier and suggests a value of 17.8. Let's take a look at values in the proximity of the outlier.
```{r}
NPO_Time_Series[4:10]
```
If we accept the substitution proposed, the series will be like `20.23 18.82 17.87 16.85 16.69 18.66 18.14`. The net result is eliminating a local minimum, hence we will also eliminate a change of sign in the differentiated series.
Let's proceed with the suggestion.
```{r}
NPO_Time_Series_clean_ar1 = NPO_Time_Series
NPO_Time_Series_clean_ar1[6] = tsoutliers(NPO_Time_Series)$replacements[1]
NPO_Time_Series_clean_ar1
```

```{r}
NPO.clean.ar1 = Arima(NPO_Time_Series_clean_ar1, order=c(1,1,0))
jarque.bera.test(NPO.clean.ar1$residuals)
```

The obtained p-value is not outstanding but for sure not close to 5%, so we cannot discard the null hypothesis that the distribution of the residuals has the same skewness and kurtosis of a normal one.

Here follows the results of the final AR(1) model.
```{r}
summary(NPO.clean.ar1)
acf2(NPO.clean.ar1$residuals)
Box.test(NPO.clean.ar1$residuals, lag=12, fitdf = 1)
```
Again, we cannot reject the null hypothesis that the model exhibits lack of fit [(Box-Ljung test)](https://www.itl.nist.gov/div898/handbook/pmc/section4/pmc4481.htm). 

### AR(2)
By performing the same exact procedure with p=2 we encounter the same problem with the same identical outlier.
For brevity we only report the results after replacing it (further details can be seen in the Rmd file).

```{r, echo=FALSE}
NPO_Time_Series_clean_ar2 = NPO_Time_Series
NPO_Time_Series_clean_ar2[6] = tsoutliers(NPO_Time_Series)$replacements[1]
NPO.clean.ar2 = Arima(NPO_Time_Series_clean_ar2, order=c(2,1,0))
summary(NPO.clean.ar2)
acf2(NPO.clean.ar2$residuals)
Box.test(NPO.clean.ar2$residuals, lag=12, fitdf = 1)
jarque.bera.test(NPO.clean.ar2$residuals)
```

We can see that the model performs overall better in terms of RMSE and in quality of the residuals auto-correlation (plot and Box test), while the Jarque Brera test seems to yield better results for the AR(0) model.

### Testing forecasting
Finally we test the forecasting capabilities of our models by using the "getrmse" function defined as follows:
```{r}
getrmse <- function(x,h,...)
{
  train.end <- time(x)[length(x)-h]   #train data end
  test.start <- time(x)[length(x)-h+1]  #test data start
  train <- window(x,end=train.end) #extract train data
  test <- window(x,start=test.start)  #extract test data
  fit <- Arima(train,...) # fit model with train data
  fc <- forecast(fit,h=h) # forecast with model
  return(accuracy(fc,test)[2,"RMSE"]) #compare forecast with test data, extract the rmse
}
```

Following the trial and error philosophy we add also the training of a MA(1) part
```{r}
NPO_Time_Series_clean_forecast = NPO_Time_Series
NPO_Time_Series_clean_forecast[6] = tsoutliers(NPO_Time_Series)$replacements[1]
getrmse(NPO_Time_Series_clean_forecast,h=20,order=c(0,1,0))
getrmse(NPO_Time_Series_clean_forecast,h=20,order=c(1,1,0))
getrmse(NPO_Time_Series_clean_forecast,h=20,order=c(2,1,0)) # the best AR model
getrmse(NPO_Time_Series_clean_forecast,h=20,order=c(0,1,1))
getrmse(NPO_Time_Series_clean_forecast,h=20,order=c(2,1,1)) #the actual best
```

The actual best model appears to be the last and most complicated one, but the difference in RMSE is really small. While between the aforementioned AR models the AR(2) confirms to be the best one also in predictions.

## Selected model
First of all we discard the ARIMA model with p=2 and q=1 because the gain in accuracy is not enough to justify the increase of complexity of the model.

Considering only the AR models, we choose to pick the AR(2) model as it consistenty has better accuracy, both for RMSE and MAE. It also has a better configuration of the auto-correlation coefficients of the residuals as none of them are outside the confidence range centered in zero. After the removal of the outlier it passes the Jarque-Brera test for normality of skewness and kurtosis of the residuals distribution.


##Conclusions
The obtained ARIMA model is a non-seasonal additive AR(2) model, with degree of differentiation equal to 1. This means that the value of the model at time "t" depends on a linear combination of the previous two.
The obtained RMSE for the fitting is 0.65 while the mean absolute error is 0.5. Considering the average value of 16.15 the fitting error seems to be a good performance.

Thinking about the forecasting outcome, we have obtained an RMSE of 1.97 which, gives a certain level of freedom and it is not sufficiently accurate for telling if the price will go up and down, which is the main point of forecasting this kind of data.

##Notes
We put a special effort in reporting the process of the selection of the ARIMA model as somewhat linear. This does not coincide at all with the reality. The truth is that a lot of trial and error was involved in getting the results.

We purposely left auto the usage of automatic techniques for ARIMA model selection, as it was outside the scope of the Box-Jenkins methodology.